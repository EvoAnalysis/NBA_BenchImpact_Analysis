from nba_api.stats.endpoints import leaguegamefinder
import pandas as pd
import time
import pickle

# Only from 1983‚Äì84 onward (nba_api has data)
seasons = [f"{year}-{str(year + 1)[-2:]}" for year in range(1983, 2024)]

regular_ids = []
playoff_ids = []

for season in seasons:
    print(f"\nSeason: {season}")
    
    # === Regular Season ===
    time.sleep(1)
    reg = leaguegamefinder.LeagueGameFinder(
        season_nullable=season,
        season_type_nullable="Regular Season"
    )
    reg_df = reg.get_data_frames()[0]
    regular_ids.extend(reg_df["GAME_ID"].unique().tolist())
    print(f"Regular games: {len(reg_df)}")

    # === Playoffs ===
    time.sleep(1)
    po = leaguegamefinder.LeagueGameFinder(
        season_nullable=season,
        season_type_nullable="Playoffs"
    )
    po_df = po.get_data_frames()[0]
    playoff_ids.extend(po_df["GAME_ID"].unique().tolist())
    print(f"Playoff games: {len(po_df)}")

# Save both sets
with open("data/raw/regular_season_ids.pkl", "wb") as f:
    pickle.dump(list(set(regular_ids)), f)

with open("data/raw/playoff_ids.pkl", "wb") as f:
    pickle.dump(list(set(playoff_ids)), f)

print("\n‚úÖ GAME_IDs saved for both Regular Season and Playoffs")



import pickle
import time
import os
from nba_api.stats.endpoints import boxscoretraditionalv2
import pandas as pd
import glob

# === Load PLAYOFF GAME_IDs ===
with open('data/raw/playoff_ids.pkl', 'rb') as f:
    all_game_ids = pickle.load(f)

# === Check existing batches ===
batch_files = glob.glob('data/raw/boxscores_playoff_batch_*.pkl')
batch_files.sort()

games_done = len(batch_files) * 200
remaining_game_ids = all_game_ids[games_done:]

print(f"‚úÖ Found {len(batch_files)} batches already saved.")
print(f"üîÅ Resuming from game {games_done + 1} of {len(all_game_ids)}")
print(f"üóÇÔ∏è  Remaining GAME_IDs to process: {len(remaining_game_ids)}")

# === Parameters ===
batch_size = 200
batch_data = []
failed_ids = []

# === Main Loop ===
for i, game_id in enumerate(remaining_game_ids, start=games_done + 1):
    try:
        print(f"üì• Pulling game {i}: {game_id}")
        time.sleep(1)

        boxscore = boxscoretraditionalv2.BoxScoreTraditionalV2(game_id=game_id)
        df = boxscore.get_data_frames()[0]

        # Filter for bench players
        bench_df = df[df['START_POSITION'] == '']
        bench_df['GAME_ID'] = game_id

        batch_data.append(bench_df)

        # Save every batch
        if i % batch_size == 0:
            batch_num = i // batch_size
            out_path = f'data/raw/boxscores_playoff_batch_{batch_num}.pkl'
            pd.concat(batch_data).to_pickle(out_path)
            print(f"‚úÖ Saved batch {batch_num} to {out_path}")
            batch_data = []

    except Exception as e:
        print(f"‚ùå Failed to pull game {game_id}: {e}")
        failed_ids.append(game_id)

# Save any leftover records
if batch_data:
    batch_num = (games_done + len(remaining_game_ids)) // batch_size + 1
    out_path = f'data/raw/boxscores_playoff_batch_{batch_num}.pkl'
    pd.concat(batch_data).to_pickle(out_path)
    print(f"‚úÖ Saved final (partial) batch {batch_num}")

# Save failed IDs
if failed_ids:
    with open('logs/failed_playoff_ids.txt', 'a') as f:
        for fail_id in failed_ids:
            f.write(f"{fail_id}\n")
    print(f"‚ö†Ô∏è  Logged {len(failed_ids)} failed game IDs")



import os
print("Current working directory:", os.getcwd())



os.path.exists("data/raw/playoff_ids.pkl")





